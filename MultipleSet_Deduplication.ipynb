{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+--------------------+----------+--------------------+------------------+---------+\n",
      "|unique_id|first_name|  surname|       dob|               email|CHI_Number|             address|             phone| postcode|\n",
      "+---------+----------+---------+----------+--------------------+----------+--------------------+------------------+---------+\n",
      "|        1|   Yesenia|     Sosa|1996-03-05| jared47@example.net|   000275Z|461 Davila Cove S...|  705-346-7155x236| NY 23398|\n",
      "|        2|     Tammy|    Jones|1942-04-10|wilsoncaitlin@exa...|   0002962|3235 Patterson Ex...|(361)937-6629x0692| TX 62203|\n",
      "|        3|    Joseph|Cervantes|1915-10-01|longkimberly@exam...|    00033Q|33646 Smith Islan...|      545-506-3491| MT 12286|\n",
      "|        4|   Timothy|    Young|2019-03-17|ihernandez@exampl...|    0006WP|6306 Andrews Vall...| 544-618-4901x9242| VT 80875|\n",
      "|        5| Stephanie|     Lane|1921-10-25|masonrhonda@examp...|    000RQL|745 Kathryn Exten...|  804.548.5638x391| TX 46562|\n",
      "+---------+----------+---------+----------+--------------------+----------+--------------------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----------+--------+----------+--------------------+----------+--------------------+--------------------+---------+\n",
      "|           unique_id| first_name| surname|       dob|               email|CHI_Number|             address|               phone| postcode|\n",
      "+--------------------+-----------+--------+----------+--------------------+----------+--------------------+--------------------+---------+\n",
      "|6E750588-E1AB-451...|   Michelle|   Allen|1963-04-25|                NULL|    657LEB|PSC 7915, Box 426...|001-847-296-0174x...| AP 90610|\n",
      "|511BA935-BFD2-4FE...|    Zachary|Gonzalez|1984-11-19|                NULL|    0826KM|2501 Turner Green...|  441-509-9242x19913| VA 56734|\n",
      "|BA416DE7-3D9F-49C...|     George|  Greene|2019-04-22|                NULL|    702UCL|871 Eugene Well\\n...|     +1-380-388-6653| UT 30414|\n",
      "|3FAE1533-4030-46E...|   Kimberly|  Mooney|1929-03-15|alicialambert@exa...|   6CG8584|PSC 9021, Box 234...|    371.729.0499x430| AP 76700|\n",
      "|8EFEAC05-3EB6-4EA...|Christopher|  Brooks|1949-02-22|                NULL|  3Z6F5MSF|44783 Emily Turnp...|  946-765-9050x62435| ID 38086|\n",
      "+--------------------+-----------+--------+----------+--------------------+----------+--------------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+----------+-------+----------+--------------------+----------+--------------------+--------------------+----------+\n",
      "|unique_id|first_name|surname|       dob|               email|CHI_Number|             address|               phone|  postcode|\n",
      "+---------+----------+-------+----------+--------------------+----------+--------------------+--------------------+----------+\n",
      "|        1|     Jason|Maynard|1964-07-19|kathleenfrey@exam...|   000 SUI|4198 Hansen Alley...|001-882-405-2914x...|IN 81426  |\n",
      "|        2| Stephanie|  Price|2002-06-04|chavezsandra@exam...|  00-00910|58247 Nelson Lodg...|001-738-487-6513x395|FM 81542  |\n",
      "|        3|       Amy|  Allen|1940-01-19|sharon17@example.net|      0007|03025 Bell Ramp A...| +1-961-331-5014x631|ND 07705  |\n",
      "|        4|     David| Henson|1934-09-09|beckchristopher@e...|     000CQ|839 Sara Rapids\\n...|+1-910-648-4485x6...|VI 05363  |\n",
      "|        5|    Marcus|  Wells|1966-04-22|halesusan@example...|    002WFM|39860 Tina Estate...|  677-353-1378x88154|PR 60597  |\n",
      "+---------+----------+-------+----------+--------------------+----------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import altair as alt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pandas as pd \n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "sparkdriver = SparkSession.builder.master('local').appName('demoapp') \\\n",
    "    .config('spark.jars.packages', 'com.microsoft.sqlserver:mssql-jdbc:9.4.1.jre8') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_1 = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=HealthSystem') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'SELECT [unique_id]      ,[first_name]      ,[surname]      , cast([dob] as varchar(50)) dob      ,[email]      ,[CHI_Number]      ,[address]      ,Phone_number as phone     ,[postcode]  FROM [dbo].[PatientData]') \\\n",
    "    .load()\n",
    "\n",
    "df_2 = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=HealthSystem') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'SELECT [unique_id]      ,[first_name]      ,[surname]      ,cast([dob] as varchar(50)) dob     ,[email]      ,[CHI_Number]      ,[address]      ,Phone_number as phone      ,[postcode]  FROM [dbo].[LegacyPatientData]') \\\n",
    "    .load()\n",
    "\n",
    "df_3 = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=CouncilData') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'SELECT [unique_id]      ,[first_name]      ,[surname]      ,cast([dob] as varchar(50)) dob     ,[email]      ,[CHI_Number]      ,[address]      ,[phone]      ,[postcode]  FROM [CouncilData].[dbo].[ResidentData]') \\\n",
    "    .load()\n",
    "\n",
    "sparkdriver.udf.registerJavaFunction('jaro_winkler', 'uk.gov.moj.dash.linkage.JaroWinklerSimilarity', DoubleType())\n",
    "\n",
    "df_1.show(5)\n",
    "df_2.show(5)\n",
    "df_3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import splink.spark.comparison_template_library as ctl\n",
    "import splink.spark.comparison_library as cl\n",
    "from splink.spark.blocking_rule_library import block_on\n",
    "from functools import wraps\n",
    "\n",
    "import splink.spark.comparison_library as cl\n",
    "import splink.spark.comparison_template_library as ctl\n",
    "from splink.spark.blocking_rule_library import block_on\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"link_and_dedupe\",\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.name_comparison(\"CHI_Number\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=False),\n",
    "        cl.exact_match(\"email\", term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        \"l.first_name = r.first_name and l.surname = r.surname\",\n",
    "        \"l.dob = r.dob\",  # Replace the Comparison object with a string here\n",
    "        \"l.CHI_Number = r.CHI_Number\",\n",
    "        block_on(\"postcode\"),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"max_iterations\": 10,\n",
    "    \"em_convergence\": 0.01\n",
    "}\n",
    "from splink.spark.linker import SparkLinker\n",
    "linker = SparkLinker([df_1, df_2, df_3], settings, spark=sparkdriver)\n",
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) <= 2\",\n",
    "    \"levenshtein(r.first_name, l.first_name) <= 2 and levenshtein(r.surname, l.surname) <= 2\",\n",
    "    \"levenshtein(r.CHI_Number, l.CHI_Number) <= 2\"\n",
    "    ]\n",
    "\n",
    "sc = sparkdriver.sparkContext  # Access the SparkContext\n",
    "sc.setCheckpointDir(\"C:/Users/seanj/Documents/MyProjects/Splink\")  # Set checkpoint directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Probability two random records match is estimated to be  0.00022.\n",
      "This means that amongst all possible pairwise record comparisons, one in 4,551.29 are expected to match.  With 66,084,756 total possible comparisons, we expect a total of around 14,520.00 matching pairs\n",
      "----- Estimating u probabilities using random sampling -----\n",
      "u probability not trained for CHI_Number - Exact match CHI_Number (comparison vector value: 4). This usually means the comparison level was never observed in the training data.\n",
      "u probability not trained for CHI_Number - Damerau_levenshtein <= 1 (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - CHI_Number (some u values are not trained, no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - email (no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.first_name = r.first_name and l.surname = r.surname\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - CHI_Number\n",
      "    - dob\n",
      "    - email\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - first_name\n",
      "    - surname\n",
      "\n",
      "WARNING:\n",
      "Level Damerau_levenshtein <= 1 on comparison CHI_Number not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.9 on comparison CHI_Number not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.8 on comparison CHI_Number not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Within 1 month on comparison dob not observed in dataset, unable to train m value\n",
      "\n",
      "Iteration 1: Largest change in params was -0.901 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was 0.0229 in the m_probability of email, level `Exact match`\n",
      "Iteration 3: Largest change in params was -0.00695 in the m_probability of email, level `All other comparisons`\n",
      "\n",
      "EM converged after 3 iterations\n",
      "m probability not trained for CHI_Number - Damerau_levenshtein <= 1 (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for CHI_Number - Jaro_winkler >= 0.9 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for CHI_Number - Jaro_winkler >= 0.8 (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for dob - Within 1 month (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - CHI_Number (some u values are not trained, some m values are not trained).\n",
      "    - dob (some m values are not trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.dob = r.dob\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - CHI_Number\n",
      "    - email\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.9 on comparison surname not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Damerau_levenshtein <= 1 on comparison CHI_Number not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.9 on comparison CHI_Number not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.8 on comparison CHI_Number not observed in dataset, unable to train m value\n",
      "\n",
      "Iteration 1: Largest change in params was -0.89 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was -1.23e-07 in the m_probability of email, level `All other comparisons`\n",
      "\n",
      "EM converged after 2 iterations\n",
      "m probability not trained for surname - Jaro_winkler >= 0.9 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for CHI_Number - Damerau_levenshtein <= 1 (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for CHI_Number - Jaro_winkler >= 0.9 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for CHI_Number - Jaro_winkler >= 0.8 (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - surname (some m values are not trained).\n",
      "    - CHI_Number (some u values are not trained, some m values are not trained).\n",
      "    - dob (some m values are not trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.CHI_Number = r.CHI_Number\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - dob\n",
      "    - email\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - CHI_Number\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.9 on comparison surname not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Jaro_winkler >= 0.8 on comparison surname not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison surname not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Within 1 month on comparison dob not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level Within 10 years on comparison dob not observed in dataset, unable to train m value\n",
      "\n",
      "WARNING:\n",
      "Level All other comparisons on comparison dob not observed in dataset, unable to train m value\n",
      "\n",
      "Iteration 1: Largest change in params was 0.916 in probability_two_random_records_match\n",
      "Iteration 2: Largest change in params was 0.107 in the m_probability of email, level `All other comparisons`\n",
      "Iteration 3: Largest change in params was -4.55e-06 in the m_probability of email, level `Exact match`\n",
      "\n",
      "EM converged after 3 iterations\n",
      "m probability not trained for surname - Jaro_winkler >= 0.9 (comparison vector value: 2). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for surname - Jaro_winkler >= 0.8 (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for surname - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for dob - Within 1 month (comparison vector value: 3). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for dob - Within 10 years (comparison vector value: 1). This usually means the comparison level was never observed in the training data.\n",
      "m probability not trained for dob - All other comparisons (comparison vector value: 0). This usually means the comparison level was never observed in the training data.\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - surname (some m values are not trained).\n",
      "    - CHI_Number (some u values are not trained, some m values are not trained).\n",
      "    - dob (some m values are not trained).\n",
      "\n",
      " -- WARNING --\n",
      "You have called predict(), but there are some parameter estimates which have neither been estimated or specified in your settings dictionary.  To produce predictions the following untrained trained parameters will use default values.\n",
      "Comparison: 'surname':\n",
      "    m values not fully trained\n",
      "Comparison: 'CHI_Number':\n",
      "    m values not fully trained\n",
      "Comparison: 'CHI_Number':\n",
      "    u values not fully trained\n",
      "Comparison: 'dob':\n",
      "    m values not fully trained\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.6)\n",
    "linker.estimate_u_using_random_sampling(max_pairs=5e5)\n",
    "\n",
    "training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "training_session_fname_sname = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n",
    "\n",
    "training_blocking_rule = \"l.dob = r.dob\"\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n",
    "\n",
    "training_blocking_rule = \"l.CHI_Number = r.CHI_Number\"\n",
    "training_session_chi_number = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n",
    "\n",
    "results = linker.predict(threshold_match_probability=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to results.csv successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_e = results.as_pandas_dataframe()\n",
    "df_e.to_csv('OutputFull.csv')\n",
    "\n",
    "print(\"Results written to results.csv successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_e is your DataFrame containing the results\n",
    "\n",
    "# Create a dictionary to store mappings between original IDs and unified/common ID\n",
    "id_mapping = {}\n",
    "\n",
    "# Assign the same unified/common ID to linked individuals\n",
    "linked_individuals = df_e[df_e['match_probability'] >= 0.9]  # Assuming match_probability >= 0.9 indicates a match\n",
    "for index, row in linked_individuals.iterrows():\n",
    "    if row['unique_id_l'] not in id_mapping:\n",
    "        id_mapping[row['unique_id_l']] = len(id_mapping) + 1\n",
    "    if row['unique_id_r'] not in id_mapping:\n",
    "        id_mapping[row['unique_id_r']] = len(id_mapping) + 1\n",
    "\n",
    "# Generate new unified/common IDs for individuals not linked\n",
    "not_linked_individuals = df_e[df_e['match_probability'] < 0.9]\n",
    "for index, row in not_linked_individuals.iterrows():\n",
    "    if row['unique_id_l'] not in id_mapping:\n",
    "        id_mapping[row['unique_id_l']] = len(id_mapping) + 1\n",
    "    if row['unique_id_r'] not in id_mapping:\n",
    "        id_mapping[row['unique_id_r']] = len(id_mapping) + 1\n",
    "\n",
    "# Update the DataFrame with unified/common IDs\n",
    "df_e['unified_id_l'] = df_e['unique_id_l'].map(id_mapping)\n",
    "df_e['unified_id_r'] = df_e['unique_id_r'].map(id_mapping)\n",
    "\n",
    "# Store the mapping in a database (Assuming you're using SQLAlchemy for database operations)\n",
    "\n",
    "# Create an SQLAlchemy engine connected to the SQL Server database\n",
    "engine = create_engine('mssql+pyodbc://datahubadmin:datahub@localhost:47777/Splink?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "\n",
    "# Create if not exists scripts\n",
    "create_id_mapping_table_script = '''\n",
    "CREATE TABLE IF NOT EXISTS id_mapping_table (\n",
    "    original_id VARCHAR(255),\n",
    "    unified_id INT\n",
    ")\n",
    "'''\n",
    "\n",
    "create_linked_individuals_table_script = '''\n",
    "CREATE TABLE IF NOT EXISTS linked_individuals_table (\n",
    "    match_weight FLOAT,\n",
    "    match_probability FLOAT,\n",
    "    source_dataset_l VARCHAR(255),\n",
    "    source_dataset_r VARCHAR(255),\n",
    "    unique_id_l VARCHAR(255),\n",
    "    unique_id_r VARCHAR(255),\n",
    "    first_name_l VARCHAR(255),\n",
    "    first_name_r VARCHAR(255),\n",
    "    gamma_first_name INT,\n",
    "    bf_first_name FLOAT,\n",
    "    surname_l VARCHAR(255),\n",
    "    surname_r VARCHAR(255),\n",
    "    gamma_surname INT,\n",
    "    bf_surname FLOAT,\n",
    "    CHI_Number_l VARCHAR(255),\n",
    "    CHI_Number_r VARCHAR(255),\n",
    "    gamma_CHI_Number INT,\n",
    "    bf_CHI_Number FLOAT,\n",
    "    dob_l DATE,\n",
    "    dob_r DATE,\n",
    "    gamma_dob INT,\n",
    "    bf_dob FLOAT,\n",
    "    email_l VARCHAR(255),\n",
    "    email_r VARCHAR(255),\n",
    "    gamma_email INT,\n",
    "    tf_email_l FLOAT,\n",
    "    tf_email_r FLOAT,\n",
    "    bf_email FLOAT,\n",
    "    bf_tf_adj_email FLOAT,\n",
    "    postcode_l VARCHAR(255),\n",
    "    postcode_r VARCHAR(255),\n",
    "    match_key INT,\n",
    "    unified_id_l INT,\n",
    "    unified_id_r INT\n",
    ")\n",
    "'''\n",
    "\n",
    "# Execute the create if not exists scripts\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_id_mapping_table_script)\n",
    "    connection.execute(create_linked_individuals_table_script)\n",
    "\n",
    "# Convert the id_mapping dictionary to a DataFrame\n",
    "id_mapping_df = pd.DataFrame(id_mapping.items(), columns=['original_id', 'unified_id'])\n",
    "\n",
    "# Store the DataFrame in the database\n",
    "id_mapping_df.to_sql('id_mapping_table', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# Store the DataFrame containing linked and not-linked individuals in the database\n",
    "df_e.to_sql('linked_individuals_table', con=engine, if_exists='append', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
