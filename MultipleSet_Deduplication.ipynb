{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import altair as alt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pandas as pd \n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "sparkdriver = SparkSession.builder.master('local').appName('demoapp') \\\n",
    "    .config('spark.jars.packages', 'com.microsoft.sqlserver:mssql-jdbc:9.4.1.jre8') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_1 = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=HealthSystem') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'SELECT [unique_id]      ,[first_name]      ,[surname]      , cast([dob] as varchar(50)) dob      ,[email]      ,[CHI_Number]      ,[address]      ,Phone_number as phone     ,[postcode]  FROM [dbo].[PatientData]') \\\n",
    "    .load()\n",
    "\n",
    "df_2 = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=HealthSystem') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'SELECT [unique_id]      ,[first_name]      ,[surname]      ,cast([dob] as varchar(50)) dob     ,[email]      ,[CHI_Number]      ,[address]      ,Phone_number as phone      ,[postcode]  FROM [dbo].[LegacyPatientData]') \\\n",
    "    .load()\n",
    "\n",
    "df_3 = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=CouncilData') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'SELECT [unique_id]      ,[first_name]      ,[surname]      ,cast([dob] as varchar(50)) dob     ,[email]      ,[CHI_Number]      ,[address]      ,[phone]      ,[postcode]  FROM [CouncilData].[dbo].[ResidentData]') \\\n",
    "    .load()\n",
    "\n",
    "sparkdriver.udf.registerJavaFunction('jaro_winkler', 'uk.gov.moj.dash.linkage.JaroWinklerSimilarity', DoubleType())\n",
    "\n",
    "df_1.show(5)\n",
    "df_2.show(5)\n",
    "df_3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import splink.spark.comparison_template_library as ctl\n",
    "import splink.spark.comparison_library as cl\n",
    "from splink.spark.blocking_rule_library import block_on\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on([\"first_name\", \"surname\"]),\n",
    "        block_on([\"surname\", \"dob\"]),\n",
    "        block_on([\"first_name\", \"dob\"]),\n",
    "        block_on([\"postcode\", \"first_name\"]),\n",
    "        block_on([\"first_name\", \"surname\", \"CHI_Number\"]),\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\", term_frequency_adjustments=True),\n",
    "        ctl.name_comparison(\"surname\", term_frequency_adjustments=True),\n",
    "        cl.exact_match(\"CHI_Number\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True, invalid_dates_as_null=True),\n",
    "        ctl.postcode_comparison(\"postcode\"),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"max_iterations\": 10,\n",
    "    \"em_convergence\": 0.01\n",
    "}\n",
    "import splink.spark.comparison_library as cl\n",
    "import splink.spark.comparison_template_library as ctl\n",
    "from splink.spark.blocking_rule_library import block_on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "settings = {\n",
    "    \"link_type\": \"link_and_dedupe\",\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=False),\n",
    "        cl.exact_match(\"email\", term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on(\"first_name\"),\n",
    "        \"l.surname = r.surname\",  # alternatively, you can write BRs in their SQL form\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"em_convergence\": 0.01\n",
    "}\n",
    "from splink.spark.linker import SparkLinker\n",
    "linker = SparkLinker([df_1, df_2, df_3], settings, spark=sparkdriver)\n",
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) <= 2\"]\n",
    "\n",
    "sc = sparkdriver.sparkContext  # Access the SparkContext\n",
    "sc.setCheckpointDir(\"C:/Users/seanj/Documents/MyProjects/Splink\")  # Set checkpoint directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.6)\n",
    "linker.estimate_u_using_random_sampling(max_pairs=5e5)\n",
    "\n",
    "training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "training_session_fname_sname = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n",
    "\n",
    "training_blocking_rule = \"l.dob = r.dob\"\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n",
    "results = linker.predict(threshold_match_probability=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_e = results.as_pandas_dataframe()\n",
    "df_e.to_csv('OutputFull.csv')\n",
    "\n",
    "print(\"Results written to results.csv successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
