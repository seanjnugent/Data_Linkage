{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+-----------------+----------+---------+----------+-----------+-------------+------+----------+\n",
      "| unique_id|     cluster|           full_name|first_and_surname|first_name|  surname|       dob|birth_place|postcode_fake|gender|occupation|\n",
      "+----------+------------+--------------------+-----------------+----------+---------+----------+-----------+-------------+------+----------+\n",
      "|Q2296770-1|2296770.0000|thomas clifford, ...| thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|     tq13 8df|  male|politician|\n",
      "|Q2296770-2|2296770.0000| thomas of chudleigh| thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|     tq13 8df|  male|politician|\n",
      "|Q2296770-3|2296770.0000|tom 1st baron cli...|    tom chudleigh|       tom|chudleigh|1630-08-01|      devon|     tq13 8df|  male|politician|\n",
      "|Q2296770-4|2296770.0000|thomas 1st chudleigh| thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|     tq13 8hu|  NULL|politician|\n",
      "|Q2296770-5|2296770.0000|thomas clifford, ...| thomas chudleigh|    thomas|chudleigh|1630-08-01|      devon|     tq13 8df|  NULL|politician|\n",
      "+----------+------------+--------------------+-----------------+----------+---------+----------+-----------+-------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splink.datasets import splink_datasets\n",
    "from splink.duckdb.linker import DuckDBLinker\n",
    "import altair as alt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pandas as pd \n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "sparkdriver = SparkSession.builder.master('local').appName('demoapp') \\\n",
    "    .config('spark.jars.packages', 'com.microsoft.sqlserver:mssql-jdbc:9.4.1.jre8') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = sparkdriver.read.format('jdbc') \\\n",
    "    .option('url', 'jdbc:sqlserver://localhost:47777;databaseName=splink') \\\n",
    "    .option('driver', 'com.microsoft.sqlserver.jdbc.SQLServerDriver') \\\n",
    "    .option('user', 'datahubadmin') \\\n",
    "    .option('password', 'datahub') \\\n",
    "    .option('query', 'select * from dbo.inputfull') \\\n",
    "    .load()\n",
    "\n",
    "sparkdriver.udf.registerJavaFunction('jaro_winkler', 'uk.gov.moj.dash.linkage.JaroWinklerSimilarity', DoubleType())\n",
    "\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d9db098e18424c5f8fb277bd96d55111.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d9db098e18424c5f8fb277bd96d55111.vega-embed details,\n",
       "  #altair-viz-d9db098e18424c5f8fb277bd96d55111.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d9db098e18424c5f8fb277bd96d55111\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d9db098e18424c5f8fb277bd96d55111\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d9db098e18424c5f8fb277bd96d55111\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f503dad803b9e55862d33c78784ee5e1\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"rule\", \"legend\": null, \"scale\": {\"scheme\": \"category20c\"}}, \"order\": {\"field\": \"cumulative_rows\"}, \"tooltip\": [{\"field\": \"rule\", \"title\": \"SQL Condition\", \"type\": \"nominal\"}, {\"field\": \"row_count\", \"format\": \",\", \"title\": \"Comparisons Generated\", \"type\": \"quantitative\"}, {\"field\": \"cumulative_rows\", \"format\": \",\", \"title\": \"Cumulative Comparisons\", \"type\": \"quantitative\"}, {\"field\": \"cartesian\", \"format\": \",\", \"title\": \"Cartesian Product of Input Data\", \"type\": \"quantitative\"}, {\"field\": \"reduction_ratio\", \"title\": \"Reduction Ratio (cumulative rows/cartesian product)\", \"type\": \"nominal\"}], \"x\": {\"field\": \"start\", \"title\": \"Comparisons Generated by Rule(s)\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"cumulative_rows\"}, \"y\": {\"field\": \"rule\", \"sort\": [\"-x2\"], \"title\": \"SQL Blocking Rule\"}}, \"height\": {\"step\": 20}, \"title\": {\"text\": \"Count of Additional Comparisons Generated by Each Blocking Rule\", \"subtitle\": \"(Counts exclude comparisons already generated by previous rules)\"}, \"width\": 450, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.9.3.json\", \"datasets\": {\"data-f503dad803b9e55862d33c78784ee5e1\": [{\"row_count\": 243656, \"rule\": \"(l.`first_name` = r.`first_name`) AND (l.`surname` = r.`surname`)\", \"cumulative_rows\": 243656, \"cartesian\": 1279041753, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.99981. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 0}, {\"row_count\": 25041, \"rule\": \"(l.`surname` = r.`surname`) AND (l.`dob` = r.`dob`)\", \"cumulative_rows\": 268697, \"cartesian\": 1279041753, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.99979. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 243656}, {\"row_count\": 29905, \"rule\": \"(l.`first_name` = r.`first_name`) AND (l.`dob` = r.`dob`)\", \"cumulative_rows\": 298602, \"cartesian\": 1279041753, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.999767. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 268697}, {\"row_count\": 8421, \"rule\": \"(l.`postcode_fake` = r.`postcode_fake`) AND (l.`first_name` = r.`first_name`)\", \"cumulative_rows\": 307023, \"cartesian\": 1279041753, \"reduction_ratio\": \"The rolling reduction ratio with your given blocking rule(s) is 0.99976. This represents the reduction in the total number of comparisons due to your rule(s).\", \"start\": 298602}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from splink.spark.blocking_rule_library import block_on\n",
    "\n",
    "# Simple settings dictionary will be used for exploratory analysis\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on([\"first_name\", \"surname\"]),\n",
    "        block_on([\"surname\", \"dob\"]),\n",
    "        block_on([\"first_name\", \"dob\"]),\n",
    "        block_on([\"postcode_fake\", \"first_name\"]),\n",
    "    ],\n",
    "}\n",
    "\n",
    "from splink.spark.linker import SparkLinker\n",
    "linker = SparkLinker(df, settings, spark=sparkdriver)\n",
    "\n",
    "linker.profile_columns(\n",
    "    [\"first_name\", \"postcode_fake\", \"substr(dob, 1,4)\"], top_n=10, bottom_n=5\n",
    ")\n",
    "\n",
    "linker.cumulative_num_comparisons_from_blocking_rules_chart()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import splink.spark.comparison_template_library as ctl\n",
    "import splink.spark.comparison_library as cl\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on([\"first_name\", \"surname\"]),\n",
    "        block_on([\"surname\", \"dob\"]),\n",
    "        block_on([\"first_name\", \"dob\"]),\n",
    "        block_on([\"postcode_fake\", \"first_name\"]),\n",
    "    ],\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\", term_frequency_adjustments=True),\n",
    "        ctl.name_comparison(\"surname\", term_frequency_adjustments=True),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True, invalid_dates_as_null=True),\n",
    "        ctl.postcode_comparison(\"postcode_fake\"),\n",
    "        cl.exact_match(\"birth_place\", term_frequency_adjustments=True),\n",
    "        cl.exact_match(\"occupation\",  term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"max_iterations\": 10,\n",
    "    \"em_convergence\": 0.01\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splink.spark.comparison_library as cl\n",
    "import splink.spark.comparison_template_library as ctl\n",
    "from splink.spark.blocking_rule_library import block_on\n",
    "\n",
    "settings = {\n",
    "    \"link_type\": \"dedupe_only\",\n",
    "    \"comparisons\": [\n",
    "        ctl.name_comparison(\"first_name\"),\n",
    "        ctl.name_comparison(\"surname\"),\n",
    "        ctl.date_comparison(\"dob\", cast_strings_to_date=True),\n",
    "        cl.exact_match(\"birth_place\", term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"blocking_rules_to_generate_predictions\": [\n",
    "        block_on(\"first_name\"),\n",
    "        \"l.surname = r.surname\",  # alternatively, you can write BRs in their SQL form\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": True,\n",
    "    \"em_convergence\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--WARN-- \n",
      " You are using datediff comparison\n",
      "                        with str-casting and ANSI is not enabled. Bad dates\n",
      "                        e.g. 1999-13-54 will not trigger an exception but will\n",
      "                        classed as comparison level = \"ELSE\". Ensure date strings\n",
      "                        are cleaned to remove bad dates \n",
      "\n",
      "Probability two random records match is estimated to be  0.000771.\n",
      "This means that amongst all possible pairwise record comparisons, one in 1,297.74 are expected to match.  With 1,279,041,753 total possible comparisons, we expect a total of around 985,588.33 matching pairs\n",
      "----- Estimating u probabilities using random sampling -----\n",
      "\n",
      "Estimated u probabilities using random sampling\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "    - dob (no m values are trained).\n",
      "    - birth_place (no m values are trained).\n"
     ]
    }
   ],
   "source": [
    "from splink.spark.linker import SparkLinker\n",
    "linker = SparkLinker(df, settings, spark=sparkdriver)\n",
    "deterministic_rules = [\n",
    "    \"l.first_name = r.first_name and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.surname = r.surname and levenshtein(r.dob, l.dob) <= 1\",\n",
    "    \"l.first_name = r.first_name and levenshtein(r.surname, l.surname) <= 2\"]\n",
    "\n",
    "sc = sparkdriver.sparkContext  # Access the SparkContext\n",
    "sc.setCheckpointDir(\"C:/Users/seanj/Documents/MyProjects/Splink\")  # Set checkpoint directory\n",
    "\n",
    "\n",
    "linker.estimate_probability_two_random_records_match(deterministic_rules, recall=0.6)\n",
    "linker.estimate_u_using_random_sampling(max_pairs=5e5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.first_name = r.first_name and l.surname = r.surname\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - dob\n",
      "    - birth_place\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - first_name\n",
      "    - surname\n",
      "\n",
      "Iteration 1: Largest change in params was -0.512 in the m_probability of dob, level `Exact match`\n",
      "Iteration 2: Largest change in params was -0.0845 in probability_two_random_records_match\n",
      "Iteration 3: Largest change in params was -0.0569 in the m_probability of birth_place, level `All other comparisons`\n",
      "Iteration 4: Largest change in params was 0.0555 in the m_probability of birth_place, level `Exact match`\n",
      "Iteration 5: Largest change in params was -0.0508 in the m_probability of birth_place, level `All other comparisons`\n",
      "Iteration 6: Largest change in params was 0.0422 in the m_probability of birth_place, level `Exact match`\n",
      "Iteration 7: Largest change in params was 0.0312 in the m_probability of birth_place, level `Exact match`\n",
      "Iteration 8: Largest change in params was -0.0204 in the m_probability of birth_place, level `All other comparisons`\n",
      "Iteration 9: Largest change in params was -0.0122 in the m_probability of birth_place, level `All other comparisons`\n",
      "Iteration 10: Largest change in params was -0.00679 in the m_probability of birth_place, level `All other comparisons`\n",
      "\n",
      "EM converged after 10 iterations\n",
      "\n",
      "Your model is not yet fully trained. Missing estimates for:\n",
      "    - first_name (no m values are trained).\n",
      "    - surname (no m values are trained).\n",
      "\n",
      "----- Starting EM training session -----\n",
      "\n",
      "Estimating the m probabilities of the model by blocking on:\n",
      "l.dob = r.dob\n",
      "\n",
      "Parameter estimates will be made for the following comparison(s):\n",
      "    - first_name\n",
      "    - surname\n",
      "    - birth_place\n",
      "\n",
      "Parameter estimates cannot be made for the following comparison(s) since they are used in the blocking rules: \n",
      "    - dob\n",
      "\n",
      "Iteration 1: Largest change in params was -0.347 in the m_probability of first_name, level `Exact match first_name`\n",
      "Iteration 2: Largest change in params was 0.0362 in the m_probability of first_name, level `All other comparisons`\n",
      "Iteration 3: Largest change in params was 0.00692 in the m_probability of first_name, level `All other comparisons`\n",
      "\n",
      "EM converged after 3 iterations\n",
      "\n",
      "Your model is fully trained. All comparisons have at least one estimate for their m and u values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_blocking_rule = \"l.first_name = r.first_name and l.surname = r.surname\"\n",
    "training_session_fname_sname = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)\n",
    "\n",
    "training_blocking_rule = \"l.dob = r.dob\"\n",
    "training_session_dob = linker.estimate_parameters_using_expectation_maximisation(training_blocking_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = linker.predict(threshold_match_probability=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to results.csv successfully!\n"
     ]
    }
   ],
   "source": [
    "df_e = results.as_pandas_dataframe()\n",
    "df_e.to_csv('OutputFull.csv')\n",
    "\n",
    "print(\"Results written to results.csv successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
